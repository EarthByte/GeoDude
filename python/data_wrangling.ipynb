{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling\n",
    "\n",
    "The raw output data from coregistration cannot be passed into machine learning model directly. So, we need to combine, filter, select and transform the raw data. The processed data will be saved in a csv file. The last colomn are the labels(assuming we are mainly doing classification here). The other columns are features. \n",
    "\n",
    "The data selection is highly related to the specific research. The ultimate goal is to identify the features which are most important to the formation of deposit. For example, some researchers might think the distance to subducting trench is important. Others might think the sea floor age is cirtical. Bring out your own hypothesis, wrangle the data accordingly and then send the data into machine learning model to be evaluated. Repeat this process until we find the most important featueres and then we can train the machine learning model to predict deposit formation on new dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92540, 33)\n",
      "(310, 4)\n",
      "The train and test data has been saved!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#load data from coregistration output folder\n",
    "input_data = np.genfromtxt('coreg_output/coregistration_input_data_example.csv',delimiter=',')\n",
    "conv_data=np.genfromtxt('coreg_output/0_vector_subStats.out',delimiter=',')\n",
    "seafloor_age_data=np.genfromtxt(\n",
    "    'coreg_output/0_grid_EarthByte_AREPS_v1.15_Muller_etal_2016_AgeGrid.out',delimiter=',')\n",
    "\n",
    "#concatenate data together. The last column is the lables. 1 means deposit. 0 means non-deposit\n",
    "#only the first 155 rows are deposits. \n",
    "data = np.c_[input_data, conv_data, seafloor_age_data, [1]*155+[0]*(len(input_data)-155)]\n",
    "\n",
    "#print(np.isnan(conv_data).any(axis=1).sum())\n",
    "all_non_nan_data = data[~np.isnan(data).any(axis=1)]#remove all the rows which contains nan\n",
    "\n",
    "print(data.shape)\n",
    "#print(data[:,-1].sum())\n",
    "\n",
    "#the four features\n",
    "#\"Seafloor Age\",\"Distance to Trench Edge\",\"Convergence Rate\", \"Subduction Obliquity\"\n",
    "data = all_non_nan_data[:155*2,(31,16,8,9)]\n",
    "labels = all_non_nan_data[:155*2,-1]\n",
    "print(data.shape)\n",
    "#print(labels)\n",
    "np.savetxt('machine_learning_train_test_data.csv', np.c_[data, labels], delimiter=',')\n",
    "print('The train and test data has been saved!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
